### Automated Pre-Labeling

Manual labeling is expensive and time-consuming. To reduce annotation effort, we implement an automated pre-labeling system in `labeling.py` that leverages both object detection and image segmentation.

#### Input
The input consists of unlabeled wildfire-related images from the project dataset.

#### Process

**Object Detection and Segmentation (`labeling.py`)**

A YOLOv8 model [@yolo2020] is applied to each image to generate bounding boxes, class labels (e.g., fire, smoke, vehicle), and confidence scores. These predictions are then passed to the Segment Anything Model (SAM) [@sam2023], which generates pixel-level segmentation masks using the YOLO-generated bounding boxes and labels as prompts.

![Overview of the proposed labeling pipeline combining YOLO for object detection, SAM for segmentation, and a matching process.](img/prelabelling_1.png){width=50%}

**Matching and Filtering (`matching.py`)**

To reconcile YOLO’s bounding boxes with SAM’s segmentation masks, the `matching.py` script implements a function that compares the predicted masks and boxes using either Intersection over Union (IoU) or mask containment. If the overlap is below a predefined threshold, the annotation is flagged as uncertain.

![Visual comparison of YOLO's bounding box and SAM's segmentation mask, highlighting the need for a matching criterion.](img/prelabelling_2.png){width=100%}

#### Output
Images with high-confidence matches are automatically labeled. Those with low-confidence results are passed to human annotators for validation in the next stage.

### Human-in-the-Loop Review

Some predictions from the pre-labeling stage may be ambiguous or inaccurate. These cases are handled in `human_intervention.py`, which integrates with **Label Studio**, an open-source annotation platform [@labelstudio].

#### Input
The input includes uncertain or low-confidence image annotations from the matching stage.

#### Process
Human annotators review and correct the predicted bounding boxes and segmentation masks using a customized Label Studio interface that displays both YOLO and SAM outputs. This manual verification ensures that the final annotations are of high quality and suitable for training.

![Human-in-the-loop flow using Label Studio to validate flagged predictions.](img/prelabelling_3.png){width=70%}

![Label Studio interface displaying pre-labeled objects for reviewer validation.](img/prelabelling_4.png){width=70%}

#### Output
The output is a validated dataset of labeled wildfire images ready for training a downstream YOLOv8 model.
